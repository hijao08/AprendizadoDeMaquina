import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from xgboost import XGBRegressor
from sklearn.linear_model import LinearRegression

# -------------------------------
# 1. Carregar dados e filtrar N2O
# -------------------------------
df = pd.read_csv("./data/input/br_seeg_emissoes_brasil.csv")

# Filtra apenas registros com g√°s N2O
df_n2o = df[df["gas"] == "N2O (t)"].copy()

# Remove linhas com emiss√£o nula (NaN)
df_n2o = df_n2o[df_n2o["emissao"].notna()]

# Remove a coluna 'gas' ap√≥s o filtro
df_n2o.drop(columns=["gas"], inplace=True)

# Garante a exist√™ncia da pasta de sa√≠da
os.makedirs("./data/output", exist_ok=True)

# -----------------------------
# 2. Tratamento de valores nulos
# -----------------------------
for col in df_n2o.columns:
    if df_n2o[col].dtype == "object":
        df_n2o[col] = df_n2o[col].fillna("desconhecido")
    else:
        df_n2o[col] = df_n2o[col].fillna(0)

# -----------------------------
# 3. An√°lise explorat√≥ria
# -----------------------------
print("\nüìå Dimens√µes do dataframe filtrado (apenas N2O):")
print(df_n2o.shape)
print("\nüßæ Primeiras linhas:")
print(df_n2o.head())
print("\nüîç Tipos de dados:")
print(df_n2o.dtypes)
print("\n‚ùì Valores nulos:")
print(df_n2o.isnull().sum())
print("\nüìä Estat√≠sticas da emiss√£o:")
print(df_n2o["emissao"].describe())

# Gr√°fico: distribui√ß√£o da emiss√£o
plt.figure(figsize=(10, 5))
sns.histplot(df_n2o["emissao"], bins=30, kde=True)
plt.title("Distribui√ß√£o dos valores de emiss√£o (N2O)")
plt.xlabel("Emiss√£o (toneladas)")
plt.ylabel("Frequ√™ncia")
plt.grid(True)
plt.tight_layout()
plt.savefig("./data/output/distribuicao_emissao.png")
plt.close()

# Frequ√™ncia das categorias em nivel_1
if "nivel_1" in df_n2o.columns:
    plt.figure(figsize=(10, 4))
    sns.countplot(data=df_n2o, x="nivel_1", order=df_n2o["nivel_1"].value_counts().index)
    plt.xticks(rotation=45)
    plt.title("Frequ√™ncia por categoria - nivel_1")
    plt.tight_layout()
    plt.savefig("./data/output/frequencia_nivel1.png")
    plt.close()

# Correla√ß√£o num√©rica
plt.figure(figsize=(8, 6))
sns.heatmap(df_n2o.select_dtypes(include=[np.number]).corr(), annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Matriz de Correla√ß√£o (vari√°veis num√©ricas)")
plt.tight_layout()
plt.savefig("./data/output/correlacao_numerica.png")
plt.close()

# -----------------------------------
# 4. Prepara√ß√£o dos dados para treino
# -----------------------------------
X = df_n2o.drop(columns=["emissao"])
y = df_n2o["emissao"]

# Codifica colunas categ√≥ricas com one-hot
X = pd.get_dummies(X)

# Normaliza os dados num√©ricos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Separa√ß√£o treino/teste
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# ----------------------
# 5. Treinamento com XGBoost
# ----------------------
modelo = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, verbosity=0)
modelo.fit(X_train, y_train)

# ----------------------
# 5. Treinamento com Regress√£o Linear (Linha de Base)
# ----------------------
modelo_baseline = LinearRegression()
modelo_baseline.fit(X_train, y_train)

# -------------------------
# 6. Previs√£o e avalia√ß√£o
# -------------------------
y_pred = modelo.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"\n‚úÖ MSE (erro quadr√°tico m√©dio) - XGBoost: {mse:.2f}")

# Previs√£o e avalia√ß√£o do modelo de linha de base
y_pred_baseline = modelo_baseline.predict(X_test)
mse_baseline = mean_squared_error(y_test, y_pred_baseline)
print(f"\n‚úÖ MSE (erro quadr√°tico m√©dio) - Regress√£o Linear (Linha de Base): {mse_baseline:.2f}")

# Compara√ß√£o de melhoria
melhoria_percentual = ((mse_baseline - mse) / mse_baseline) * 100
print(f"\nüìà A linha de base √© {melhoria_percentual:.2f}% melhor que o modelo XGBoost.")

# --------------------------
# 7. Gerar CSV de resultado
# --------------------------
df_resultado = pd.DataFrame(X_test, columns=X.columns)
df_resultado["emissao_real"] = y_test.values
df_resultado["emissao_prevista"] = y_pred.round(2)

# Reorganiza colunas colocando 'ano' primeiro se existir
colunas = df_resultado.columns.tolist()
colunas_ordenadas = [c for c in ["ano"] if c in colunas] + \
                    [c for c in colunas if c not in ["ano", "emissao_real", "emissao_prevista"]] + \
                    ["emissao_real", "emissao_prevista"]
df_resultado = df_resultado[colunas_ordenadas]

df_resultado.to_csv("./data/output/resultado_previsto.csv", index=False)
print("üìÅ Arquivo 'resultado_previsto.csv' salvo com sucesso!")

# --------------------------
# 8. Gr√°fico real vs previsto
# --------------------------
plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.xlabel("Valor real")
plt.ylabel("Valor previsto")
plt.title("Compara√ß√£o: Real vs Previsto (XGBoost)")
plt.grid(True)
plt.tight_layout()
plt.savefig("./data/output/real_vs_previsto.png")
plt.close()

# -------------------------------
# 9. Feature Importance (Gr√°fico)
# -------------------------------
plt.figure(figsize=(12, 6))
importances = modelo.feature_importances_
indices = np.argsort(importances)[-20:]  # Top 20 features
plt.barh(np.array(X.columns)[indices], importances[indices])
plt.title("Import√¢ncia das Vari√°veis - XGBoost")
plt.xlabel("Score")
plt.tight_layout()
plt.savefig("./data/output/importancia_variaveis.png")
plt.close()
